# Diagnose and Fix ZhipuAI Streaming SSEError

## Problem Analysis
The error `httpx_sse._exceptions.SSEError: Expected response header Content-Type to contain 'text/event-stream', got ''` confirms that the ZhipuAI API response does not have the correct content type for streaming. This typically happens when:
1.  **Non-Streaming Response**: The API returns a normal JSON response (or error) instead of a stream, even if `stream=True` was requested.
2.  **Proxy/Network**: Something strips the headers.
3.  **LangChain Integration**: `ChatZhipuAI` in `langchain-community` might be using an older API version or incorrect parameters.

Given that ZhipuAI's API has evolved (v3 vs v4), and LangChain's wrapper might be lagging or misconfigured for the specific model `glm-4-flash`, we need to investigate the adapter.

## Proposed Solution

### 1. Verify `ChatZhipuAI` Configuration
Check if we are using the correct `model` name and if `ChatZhipuAI` supports the newer GLM-4 API correctly.

### 2. Implement Custom ZhipuAI Adapter (Robust Fix)
Instead of relying on `langchain-community.chat_models.ChatZhipuAI` which seems to have issues with `httpx-sse`, we can:
-   **Option A**: Use the official `zhipuai` Python SDK wrapped in a custom LangChain `BaseChatModel`.
-   **Option B (Chosen)**: Use `ChatOpenAI` with ZhipuAI's OpenAI-compatible endpoint. ZhipuAI provides an OpenAI-compatible API at `https://open.bigmodel.cn/api/paas/v4/`. This is often more stable and better supported by LangChain's core `ChatOpenAI` class which handles streaming robustly.

### 3. Execution Plan
1.  **Modify `deepagent/core/models.py`**:
    -   Update `ZhipuAdapter` to use `ChatOpenAI` instead of `ChatZhipuAI`.
    -   Set the `base_url` to `https://open.bigmodel.cn/api/paas/v4/`.
    -   Ensure the API key is passed correctly.
2.  **Remove `langchain-community` dependency for Zhipu**: This reduces bloat and potential version conflicts.
3.  **Verify Streaming**: Restart and test if `astream_events` works with the OpenAI-compatible adapter.

## Why this works
Using `ChatOpenAI` for ZhipuAI is the recommended best practice for modern GLM-4 models as it leverages the standard, battle-tested OpenAI streaming protocol support in LangChain, bypassing the potentially buggy or outdated specific ZhipuAI wrapper.
